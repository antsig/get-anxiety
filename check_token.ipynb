{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Fungsi untuk memuat dan menampilkan struktur file JSON\n",
    "def load_and_check_json(filepath):\n",
    "    try:\n",
    "        with open(filepath, 'r') as f:\n",
    "            data = json.load(f)\n",
    "            return data\n",
    "    except Exception as e:\n",
    "        print(f\"Terjadi kesalahan: {e}\")\n",
    "        return None\n",
    "\n",
    "# Contoh pemanggilan\n",
    "data = load_and_check_json(\"tokenizer.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File JSON valid!\n"
     ]
    }
   ],
   "source": [
    "def validate_tokenizer_json(tokenizer_json):\n",
    "    required_keys = ['config', 'word_index']\n",
    "    for key in required_keys:\n",
    "        if key not in tokenizer_json:\n",
    "            raise ValueError(f\"File JSON tidak memiliki kunci '{key}'.\")\n",
    "\n",
    "    # Validasi bagian config\n",
    "    config_keys = ['num_words', 'filters', 'lower', 'split', 'char_level', 'oov_token']\n",
    "    for key in config_keys:\n",
    "        if key not in tokenizer_json['config']:\n",
    "            raise ValueError(f\"Bagian 'config' tidak memiliki kunci '{key}'.\")\n",
    "\n",
    "    # Validasi word_index\n",
    "    if not isinstance(tokenizer_json['word_index'], dict):\n",
    "        raise ValueError(\"Bagian 'word_index' harus berupa dictionary.\")\n",
    "\n",
    "# Contoh penggunaan\n",
    "try:\n",
    "    tokenizer_json = load_and_check_json(\"tokenizer.json\")\n",
    "    if tokenizer_json:\n",
    "        validate_tokenizer_json(tokenizer_json)\n",
    "        print(\"File JSON valid!\")\n",
    "except ValueError as e:\n",
    "    print(f\"Kesalahan validasi: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Object arrays cannot be loaded when allow_pickle=False",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 19\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# Memuat dataset uji\u001b[39;00m\n\u001b[0;32m     18\u001b[0m X_test \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx_test.npy\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 19\u001b[0m y_test \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43my_test.npy\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Asumsi ini adalah label numerik (0 atau 1)\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# Preprocessing data uji\u001b[39;00m\n\u001b[0;32m     22\u001b[0m X_test_processed \u001b[38;5;241m=\u001b[39m preprocess_input(X_test, tokenizer, maxlen\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Undermedia\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\_npyio_impl.py:484\u001b[0m, in \u001b[0;36mload\u001b[1;34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001b[0m\n\u001b[0;32m    481\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m.\u001b[39mopen_memmap(file, mode\u001b[38;5;241m=\u001b[39mmmap_mode,\n\u001b[0;32m    482\u001b[0m                                   max_header_size\u001b[38;5;241m=\u001b[39mmax_header_size)\n\u001b[0;32m    483\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 484\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mformat\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_pickle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_pickle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    485\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mpickle_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpickle_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    486\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mmax_header_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_header_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    487\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    488\u001b[0m     \u001b[38;5;66;03m# Try a pickle\u001b[39;00m\n\u001b[0;32m    489\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m allow_pickle:\n",
      "File \u001b[1;32mc:\\Users\\Undermedia\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\format.py:822\u001b[0m, in \u001b[0;36mread_array\u001b[1;34m(fp, allow_pickle, pickle_kwargs, max_header_size)\u001b[0m\n\u001b[0;32m    819\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype\u001b[38;5;241m.\u001b[39mhasobject:\n\u001b[0;32m    820\u001b[0m     \u001b[38;5;66;03m# The array contained Python objects. We need to unpickle the data.\u001b[39;00m\n\u001b[0;32m    821\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m allow_pickle:\n\u001b[1;32m--> 822\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mObject arrays cannot be loaded when \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    823\u001b[0m                          \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_pickle=False\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    824\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m pickle_kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    825\u001b[0m         pickle_kwargs \u001b[38;5;241m=\u001b[39m {}\n",
      "\u001b[1;31mValueError\u001b[0m: Object arrays cannot be loaded when allow_pickle=False"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from utility import load_tokenizer_from_json\n",
    "\n",
    "# Fungsi untuk memproses input teks\n",
    "def preprocess_input(texts, tokenizer, maxlen=100):\n",
    "    sequences = tokenizer.texts_to_sequences(texts)  # Tokenisasi teks\n",
    "    padded = pad_sequences(sequences, maxlen=maxlen, padding='post', truncating='post')\n",
    "    return padded\n",
    "\n",
    "# Memuat model dan tokenizer\n",
    "model = load_model(\"best_model-2.keras\")\n",
    "tokenizer = load_tokenizer_from_json(\"tokenizer.json\")\n",
    "\n",
    "# Memuat dataset uji\n",
    "X_test = np.load(\"x_test.npy\", allow_pickle=True)\n",
    "y_test = np.load(\"y_test.npy\", allow_pickle=True)  # Asumsi ini adalah label numerik (0 atau 1)\n",
    "\n",
    "# Preprocessing data uji\n",
    "X_test_processed = preprocess_input(X_test, tokenizer, maxlen=100)\n",
    "\n",
    "# Melakukan prediksi\n",
    "predictions = model.predict(X_test_processed)\n",
    "\n",
    "# Mendapatkan confidence score untuk kelas positif (label 1)\n",
    "confidence_scores = predictions[:, 1]  # Probabilitas kelas \"Negatif\"\n",
    "\n",
    "# Plot distribusi confidence score\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(confidence_scores, bins=20, alpha=0.7, color='blue', edgecolor='black')\n",
    "plt.title(\"Distribusi Confidence Score untuk Dataset Uji\")\n",
    "plt.xlabel(\"Confidence Score (Kelas Negatif)\")\n",
    "plt.ylabel(\"Frekuensi\")\n",
    "plt.grid(axis='y')\n",
    "plt.show()\n",
    "\n",
    "# Analisis tambahan\n",
    "mean_confidence = np.mean(confidence_scores)\n",
    "std_confidence = np.std(confidence_scores)\n",
    "print(f\"Rata-rata Confidence Score: {mean_confidence:.2f}\")\n",
    "print(f\"Standar Deviasi Confidence Score: {std_confidence:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
